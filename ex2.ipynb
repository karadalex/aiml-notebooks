{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ερώτημα 2\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Diastaseis (24000, 2)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  label\n0  Entire Facebook Staff Laughs As Man Tightens P...      1\n1  Muslim Woman Denied Soda Can for Fear She Coul...      0\n2  Bold Move: Hulu Has Announced That They’re Gon...      1\n3  Despondent Jeff Bezos Realizes He’ll Have To W...      1\n4  For men looking for great single women, online...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Entire Facebook Staff Laughs As Man Tightens P...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Muslim Woman Denied Soda Can for Fear She Coul...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bold Move: Hulu Has Announced That They’re Gon...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Despondent Jeff Bezos Realizes He’ll Have To W...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>For men looking for great single women, online...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/onion-or-not.csv\")\n",
    "print(\"Diastaseis {}\".format(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργία διανύσματος λέξεων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_words = [text.split(\" \") for text in data[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επεξεργασία διανύσματος λέξεων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "processed_words = []\n",
    "\n",
    "# Stemming\n",
    "for sentence in original_words:\n",
    "    processed_words.append([ps.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Stop words removal\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(processed_words)):\n",
    "    j = 0\n",
    "    while j < len(processed_words[i]):\n",
    "        word = processed_words[i][j]\n",
    "        if word in stop_words:\n",
    "            processed_words[i].pop(j)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Υπολογισμός tf-idf μετρικής"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# N = len(processed_words)\n",
    "N = 1000\n",
    "sentence_lengths = [len(processed_words[i]) for i in range(N)]\n",
    "M = max(sentence_lengths)\n",
    "words_num = sum(sentence_lengths)\n",
    "\n",
    "# Custom code - Not working well\n",
    "# f = np.zeros([N, M])\n",
    "# for i in range(N):\n",
    "#     sentence = processed_words[i]\n",
    "#     for j in range(len(sentence)):\n",
    "#         word = sentence[j]\n",
    "#         f[i][j] = sentence.count(word) / words_num\n",
    "# tf = f/f.max()\n",
    "\n",
    "\n",
    "# def countApperances(i):\n",
    "#     dfi = []\n",
    "#     # dfi = Parallel(n_jobs=num_cores)(delayed(countWordApperances)(i,j) for j in range(len(processed_words[i])))\n",
    "#     dfi = [countWordApperances(i,j) for j in range(len(processed_words[i]))]\n",
    "#     # print(dfi)\n",
    "#     dfi = np.array(dfi)\n",
    "#     return dfi\n",
    "\n",
    "# def countWordApperances(i,j):\n",
    "#     word = processed_words[i][j]\n",
    "#     dfij = np.array([word in sentence for sentence in processed_words]).sum()\n",
    "#     return dfij\n",
    "\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# # df = Parallel(n_jobs=num_cores, verbose=10)(delayed(countApperances)(i) for i in range(N))\n",
    "# df = [countApperances(i) for i in range(N)]\n",
    "# df = np.array(df)\n",
    "\n",
    "# idf = np.zeros([N,M])\n",
    "# idf = N/df\n",
    "# idf = np.array([np.log2(idf[i]) for i in range(len(idf))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform([\" \".join(sentence) for sentence in processed_words])\n",
    "Y = data[\"label\"].to_numpy()\n",
    "N = X.shape[0]\n",
    "M = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 15787)\t0.29908528470290713\n  (0, 13909)\t0.39740171711318356\n  (0, 17847)\t0.49059179083294885\n  (0, 10882)\t0.16362201311130703\n  (0, 1494)\t0.2405785953388561\n  (0, 10193)\t0.3808735729867216\n  (0, 16742)\t0.34103916755488445\n  (0, 6513)\t0.27392624076470645\n  (0, 6162)\t0.3014653561878988\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(24000, 19902)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# tfidf.vocabulary_['entir']\n",
    "# X[0, tfidf.vocabulary_['entir']]\n",
    "print(X[0, :])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δημιουργία μοντέλου Νευρωνικού Δικτύου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Dense(M, activation='relu', input_shape=(M,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # Hidden layers\n",
    "    # tf.keras.layers.Dense(M/2),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.Dense(M/4),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.Dense(M/10),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(M/20),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(2),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 18000 samples\nEpoch 1/5\n18000/18000 [==============================] - 750s 42ms/sample - loss: 0.6960 - accuracy: 0.6244\nEpoch 2/5\n18000/18000 [==============================] - 748s 42ms/sample - loss: 0.6930 - accuracy: 0.6249\nEpoch 3/5\n18000/18000 [==============================] - 691s 38ms/sample - loss: 0.6930 - accuracy: 0.6249\nEpoch 4/5\n18000/18000 [==============================] - 669s 37ms/sample - loss: 0.6930 - accuracy: 0.6249\nEpoch 5/5\n18000/18000 [==============================] - 666s 37ms/sample - loss: 0.6930 - accuracy: 0.6249\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7facc0569a50>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for later user to avoid long training time\n",
    "model.save('./models/onion-or-not-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8ad1cec3a7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \"\"\"\n\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "print(classification_report(Y_test, Y_predicted))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593849056702",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}